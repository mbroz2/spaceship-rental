quarkus.langchain4j.chat-model.provider=ollama
# quarkus.langchain4j.chat-model.provider=openai

langchain4j-ollama-dev-service.ollama.host=localhost
langchain4j-ollama-dev-service.ollama.port=11434
langchain4j-ollama-dev-service.ollama.endpoint=http://${langchain4j-ollama-dev-service.ollama.host}:${langchain4j-ollama-dev-service.ollama.port}
quarkus.langchain4j.ollama.chat-model.model-id=qwen2.5:14b
quarkus.langchain4j.ollama.chat-model.temperature=0.0
quarkus.langchain4j.ollama.timeout=60s

# quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true